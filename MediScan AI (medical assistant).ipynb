{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":1301322,"sourceType":"datasetVersion","datasetId":752995},{"sourceId":7045374,"sourceType":"datasetVersion","datasetId":4054084}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets peft accelerate bitsandbytes trl sentence-transformers faiss-cpu streamlit opencv-python-headless sacremoses\n\n!pip install -q flash-attn --no-build-isolation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T14:00:48.970607Z","iopub.execute_input":"2026-01-11T14:00:48.970940Z","iopub.status.idle":"2026-01-11T14:01:23.827505Z","shell.execute_reply.started":"2026-01-11T14:00:48.970912Z","shell.execute_reply":"2026-01-11T14:01:23.826628Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"HF_token\")\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T14:01:41.413736Z","iopub.execute_input":"2026-01-11T14:01:41.414580Z","iopub.status.idle":"2026-01-11T14:01:42.158034Z","shell.execute_reply.started":"2026-01-11T14:01:41.414545Z","shell.execute_reply":"2026-01-11T14:01:42.157491Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Using the PubMedQA dataset (optional, I used this previously with BioGPT)\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\", split=\"train\")  \n\ndef format_example(example):\n    return {\n        \"text\": f\"You are a medical expert. Provide detailed explanation including causes, symptoms, treatments. \"\n                f\"Question: {example['question']} Context: {example.get('context', {}).get('contexts', [''])[0]} \"\n                f\"Answer: {example.get('long_answer', example.get('answer', ''))}\"\n    }\n\nformatted_dataset = dataset.map(format_example)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T09:52:28.335394Z","iopub.execute_input":"2026-01-10T09:52:28.335997Z","iopub.status.idle":"2026-01-10T09:52:40.638207Z","shell.execute_reply.started":"2026-01-10T09:52:28.335970Z","shell.execute_reply":"2026-01-10T09:52:40.637125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e023253b0f455385e369e09be6da30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pqa_labeled/train-00000-of-00001.parquet:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffa744ee2734062b82ecaabf53e0cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e7965dc73bb472fb5b9f402d3230969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"368654a770d44fb3ac1370f88c36cd3d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#Connecting skin image folders plus a bit of error handling\n\nimport os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport numpy as np\n\nIMAGE_DIR = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\nMASK_DIR = \"/kaggle/input/ham10000-lesion-segmentations/HAM10000_segmentations_lesion_tschandl\" \n\nclass SkinDataset(Dataset):\n    def __init__(self, image_dir, mask_dir):\n        if not os.path.exists(image_dir):\n            print(f\"ERROR: Path {image_dir} not found!\")\n            self.images = []\n        else:\n            self.images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n        \n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        \n    def __len__(self):\n        return len(self.images)\n        \n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n        \n        mask_name = img_name.replace('.jpg', '_segmentation.png')\n        mask_path = os.path.join(self.mask_dir, mask_name)\n        \n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (128, 128)) \n        \n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        if mask is None:\n            mask = np.zeros((128, 128))\n        else:\n            mask = cv2.resize(mask, (128, 128))\n            \n        img_tensor = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n        mask_tensor = torch.from_numpy(mask).unsqueeze(0).float() / 255.0\n        \n        return img_tensor, mask_tensor\n\nfull_dataset = SkinDataset(IMAGE_DIR, MASK_DIR)\n\nif len(full_dataset) == 0:\n    print(\"No images found. Check your IMAGE_DIR path.\")\nelse:\n    num_to_use = min(1000, len(full_dataset))\n    train_indices = np.arange(num_to_use) \n    train_subset = Subset(full_dataset, train_indices)\n    print(f\"Success! Dataset ready with {len(train_subset)} images found in {IMAGE_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T09:44:59.479744Z","iopub.execute_input":"2026-01-10T09:44:59.480054Z","iopub.status.idle":"2026-01-10T09:44:59.578438Z","shell.execute_reply.started":"2026-01-10T09:44:59.480026Z","shell.execute_reply":"2026-01-10T09:44:59.577843Z"}},"outputs":[{"name":"stdout","text":"Success! Dataset ready with 1000 images found in /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Creating the architecture for identifying tumors\n\nimport torch.nn as nn\nfrom torchvision import models\nimport torch.nn.functional as F\n\nclass MedicalUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        base = models.resnet18(pretrained=True)\n        self.encoder = nn.Sequential(*list(base.children())[:-3])         \n\n        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n        self.up4 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n        \n        self.final = nn.Conv2d(16, 1, kernel_size=1)\n\n    def forward(self, x):\n        x = self.encoder(x) \n        \n        x = F.relu(self.up1(x)) \n        x = F.relu(self.up2(x)) \n        x = F.relu(self.up3(x)) \n        x = F.relu(self.up4(x)) \n        \n        return self.final(x)\n\nmodel = MedicalUNet().cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T09:45:03.817704Z","iopub.execute_input":"2026-01-10T09:45:03.818215Z","iopub.status.idle":"2026-01-10T09:45:04.759542Z","shell.execute_reply.started":"2026-01-10T09:45:03.818187Z","shell.execute_reply":"2026-01-10T09:45:04.758848Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44.7M/44.7M [00:00<00:00, 215MB/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Training the U-Net on 1000 skin images\n\nfrom torch.optim import Adam\nfrom torch.nn import BCEWithLogitsLoss\n\ntrain_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n\noptimizer = Adam(model.parameters(), lr=1e-4)\ncriterion = BCEWithLogitsLoss()\n\nmodel.train() \nfor epoch in range(5):\n    total_loss = 0\n    for imgs, masks in train_loader:\n        imgs, masks = imgs.cuda(), masks.cuda()\n        \n        preds = model(imgs)\n        loss = criterion(preds, masks)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f}\")\n\ntorch.save(model.state_dict(), 'unet_skin.pth')\nprint(\"Model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T07:11:38.665297Z","iopub.execute_input":"2026-01-10T07:11:38.665560Z","iopub.status.idle":"2026-01-10T07:12:34.731614Z","shell.execute_reply.started":"2026-01-10T07:11:38.665537Z","shell.execute_reply":"2026-01-10T07:12:34.730965Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 | Loss: 0.6110\nEpoch 2 | Loss: 0.3034\nEpoch 3 | Loss: 0.2768\nEpoch 4 | Loss: 0.2561\nEpoch 5 | Loss: 0.2375\nModel saved.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#GPU Verification\n\nimport torch\nimport gc\n\nif 'model' in globals(): del model\nif 'text_model' in globals(): del text_model\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(f\"Is GPU Available? {torch.cuda.is_available()}\")\nprint(f\"GPU Name: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T15:49:57.559765Z","iopub.execute_input":"2026-01-10T15:49:57.560050Z","iopub.status.idle":"2026-01-10T15:49:59.466731Z","shell.execute_reply.started":"2026-01-10T15:49:57.560026Z","shell.execute_reply":"2026-01-10T15:49:59.465956Z"}},"outputs":[{"name":"stdout","text":"Is GPU Available? True\nGPU Name: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nimport cv2\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport os\nimport warnings\nimport re\n\nwarnings.filterwarnings('ignore')\n\nst.set_page_config(page_title=\"MediScan AI\", layout=\"wide\")\n\nst.markdown(\"\"\"\n    <style>\n    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap');\n\n    .stApp {\n        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);\n        font-family: 'Inter', sans-serif;\n        color: #64748b;\n    }\n\n    /* Target all text elements on light backgrounds */\n    .stApp p, .stApp span, .stApp label, .stApp div {\n        color: #64748b !important;\n    }\n\n    h1, h2, h3 {\n        color: #1e3a8a !important;\n        font-weight: 600;\n        letter-spacing: -0.5px;\n    }\n\n    .stTabs [data-baseweb=\"tab-list\"] {\n        background: transparent;\n        border-bottom: 1px solid rgba(30, 58, 138, 0.15);\n        gap: 32px;\n        padding-bottom: 8px;\n    }\n\n    .stTabs [data-baseweb=\"tab\"] {\n        color: #64748b !important;\n        font-weight: 500;\n        padding: 12px 24px;\n        transition: all 0.3s ease;\n    }\n\n    .stTabs [aria-selected=\"true\"] {\n        color: #1e3a8a !important;\n        border-bottom: 3px solid #1e3a8a;\n    }\n\n    .stTextInput > div > div > input {\n        background: rgba(255, 255, 255, 0.8);\n        border: 1px solid rgba(30, 58, 138, 0.2);\n        border-radius: 10px;\n        color: #1e293b !important;\n    }\n\n    .stButton > button {\n        background: #1e3a8a !important;\n        color: white !important;\n        border-radius: 10px;\n        border: none;\n    }\n\n    .footer {\n        position: fixed;\n        bottom: 0;\n        left: 0;\n        right: 0;\n        background: rgba(255, 255, 255, 0.9);\n        backdrop-filter: blur(10px);\n        text-align: center;\n        padding: 12px;\n        font-size: 13px;\n        color: #64748b !important;\n        border-top: 1px solid rgba(30, 58, 138, 0.1);\n        z-index: 100;\n    }\n\n    .summary-box {\n        background: rgba(255, 255, 255, 0.5);\n        border-radius: 12px;\n        padding: 20px;\n        margin-top: 20px;\n        border: 1px solid rgba(30, 58, 138, 0.1);\n    }\n    </style>\n\"\"\", unsafe_allow_html=True)\n\nclass MedicalUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        base = models.resnet18(weights=None)\n        self.encoder = nn.Sequential(*list(base.children())[:-3])\n        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n        self.up4 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n        self.final = nn.Conv2d(16, 1, kernel_size=1)\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = F.relu(self.up1(x))\n        x = F.relu(self.up2(x))\n        x = F.relu(self.up3(x))\n        x = F.relu(self.up4(x))\n        return self.final(x)\n\nMEDICAL_KB = {\n    \"hypertension\": {\n        \"definition\": \"Hypertension is persistently elevated blood pressure (≥130/80 mmHg).\",\n        \"causes\": \"Primary causes include genetics, aging, obesity, high sodium intake, sedentary lifestyle.\",\n        \"symptoms\": \"Often asymptomatic. When present: severe headaches, fatigue, vision changes.\",\n        \"treatment\": \"Lifestyle: DASH diet, exercise. Medications: ACE inhibitors, diuretics.\",\n        \"complications\": \"Heart attack, stroke, heart failure, kidney damage.\",\n    },\n    \"melanoma\": {\n        \"definition\": \"Melanoma is aggressive skin cancer from melanocytes.\",\n        \"causes\": \"UV radiation (sun, tanning beds). Risk factors: fair skin, family history.\",\n        \"symptoms\": \"ABCDE: Asymmetry, Border irregularity, Color variation, Diameter >6mm, Evolution.\",\n        \"treatment\": \"Surgical excision, immunotherapy, BRAF/MEK inhibitors.\",\n        \"complications\": \"Metastasis to lymph nodes, lungs, liver, brain.\",\n    },\n    \"diabetes\": {\n        \"definition\": \"Diabetes is chronic hyperglycemia due to insulin deficiency or resistance.\",\n        \"causes\": \"Type 1: autoimmune. Type 2: insulin resistance from obesity, genetics.\",\n        \"symptoms\": \"Polyuria, polydipsia, polyphagia, weight loss, fatigue.\",\n        \"treatment\": \"Insulin, metformin, GLP-1 agonists, lifestyle changes.\",\n        \"complications\": \"Retinopathy, nephropathy, neuropathy, CV disease.\",\n    },\n    \"skin_cancer\": {\n        \"definition\": \"Skin cancer includes BCC, SCC, and melanoma.\",\n        \"causes\": \"UV radiation, fair skin, family history.\",\n        \"symptoms\": \"Pearly papules, firm red nodules, or irregular moles.\",\n        \"treatment\": \"Surgical excision, Mohs surgery, cryotherapy.\",\n        \"complications\": \"Local tissue destruction or metastasis.\",\n    },\n    \"skin_lesion\": {\n        \"definition\": \"Skin lesion is a focal skin abnormality. Can be benign or malignant.\",\n        \"causes\": \"Genetic factors, UV damage, or infections.\",\n        \"symptoms\": \"Changes in color, size, or shape of a skin spot.\",\n        \"treatment\": \"Observation, biopsy, or surgical removal.\",\n        \"complications\": \"Risk of malignancy if left unmonitored.\",\n    }\n}\n\ndef find_condition(query):\n    clean_query = re.sub(r'[^a-zA-Z0-9\\s]', '', query.lower())\n    query_parts = clean_query.split()\n    \n    def is_close(word, target, threshold=0.75):\n        if word == target: return True\n        if abs(len(word) - len(target)) > 2: return False\n        matches = sum(1 for a, b in zip(word, target) if a == b)\n        shorter = word if len(word) < len(target) else target\n        longer = target if len(word) < len(target) else word\n        char_matches = sum(1 for char in set(shorter) if char in longer)\n        score = (matches / max(len(word), len(target)) * 0.6) + (char_matches / max(len(word), len(target)) * 0.4)\n        return score >= threshold\n\n    keyword_map = {\n    \"hypertension\": [\n        \"hypertension\", \"hypertention\", \"hipertension\", \"bloodpressure\", \"hypertenion\", \"htn\",\n        \"hypertesion\", \"hypertention\", \"hipertenstion\", \"hipertention\", \"hpertension\", \"hyperension\", \n        \"highbp\", \"hibp\", \"hi-bp\", \"hi blood pressure\", \"blod pressure\", \"blud pressure\", \"blood presure\", \n        \"blood presher\", \"blood presure\", \"hypertenssion\", \"hypertensun\", \"hypertenshun\", \"hypertensin\", \n        \"hypetension\", \"hypetention\", \"hyper-tension\", \"hibloodpressure\", \"hiper-tension\"\n    ],\n    \"melanoma\": [\n        \"melanoma\", \"malanoma\", \"melonoma\", \"melenoma\", \"malamona\", \"melanomma\", \"melanome\", \n        \"melanoman\", \"malenoma\", \"malonoma\", \"melanuma\", \"mellanoma\", \"melanmoma\", \"melenomma\", \n        \"milanoma\", \"melanooma\", \"melaanoma\", \"melanom\", \"mellanom\", \"melanomah\", \"melanom-a\", \n        \"melanomaa\", \"melanomwa\", \"melanomua\", \"melanomia\", \"melanomy\", \"malanomma\", \"melenona\"\n    ],\n    \"diabetes\": [\n        \"diabetes\", \"dibetes\", \"diabetis\", \"diabettis\", \"diabeties\", \"diabettes\", \"diabeetus\", \n        \"diabetus\", \"diabete\", \"dyabetes\", \"dyabetis\", \"diabeetes\", \"diabitis\", \"diabets\", \n        \"diabeets\", \"diabetese\", \"dibetis\", \"dibeties\", \"dia-betes\", \"diabeti\", \"diabetties\", \n        \"diabetees\", \"diabeteas\", \"diabeteus\", \"diabetiss\", \"diabetez\", \"diabetiz\", \"diabeetez\",\n        \"bloodsugar\", \"blodsugar\", \"bludsugar\", \"blod suger\", \"blood suger\"\n    ],\n    \"skin_cancer\": [\n        \"skincancer\", \"skincancr\", \"carcinoma\", \"basalcell\", \"squamouscell\", \"skincansur\", \n        \"skincanser\", \"skincansar\", \"skin-cancer\", \"skin cancr\", \"skin canser\", \"skincancer\", \n        \"skn cancer\", \"skin cancsr\", \"skincancre\", \"skin-cancr\", \"basalcel\", \"bazalcell\", \n        \"basal-cell\", \"basal cell\", \"baselcell\", \"squamous\", \"squamus\", \"sqamous\", \"squamuscell\", \n        \"squamose\", \"squamos\", \"scc\", \"bcc\", \"epithelioma\"\n    ],\n    \"skin_lesion\": [\n        \"lesion\", \"lession\", \"lesoin\", \"mole\", \"spot\", \"growth\", \"nevus\", \"leision\", \"leesion\", \n        \"leison\", \"leson\", \"lezhun\", \"leashun\", \"leashon\", \"leshin\", \"leshuon\", \"skin-lesion\", \n        \"skinlesion\", \"skinleison\", \"skin lesion\", \"moles\", \"moule\", \"mowl\", \"moal\", \"birthmark\", \n        \"nevi\", \"neveus\", \"nevous\", \"nivas\", \"niveus\", \"skingrowth\", \"skinspot\"\n    ]\n}\n\n    for cond, targets in keyword_map.items():\n        for target in targets:\n            if any(is_close(part, target) for part in query_parts) or target in clean_query:\n                return cond, MEDICAL_KB[cond]\n    return None, None\n\n@st.cache_resource\ndef load_models():\n    vision_model = None\n    if torch.cuda.is_available():\n        try:\n            vision_model = MedicalUNet().cuda()\n            if os.path.exists('/kaggle/working/unet_skin.pth'):\n                vision_model.load_state_dict(torch.load('/kaggle/working/unet_skin.pth'))\n                vision_model.eval()\n        except: pass\n    \n    text_model, tokenizer = None, None\n    try:\n        if torch.cuda.is_available():\n            bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n            text_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", quantization_config=bnb_config, device_map=\"auto\", trust_remote_code=True)\n            tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n            tokenizer.pad_token = tokenizer.eos_token\n    except: pass\n    return vision_model, text_model, tokenizer\n\nvision_model, text_model, tokenizer = load_models()\n\ndef generate_answer(query, info):\n    if not text_model or not tokenizer or not info: return None\n    focus = f\"{info['definition']} {info['symptoms']}\"\n    prompt = f\"### Medical Question\\n{query}\\n\\n### Relevant Medical Information\\n{focus}\\n\\n### Answer\\n\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(text_model.device)\n    with torch.no_grad():\n        outputs = text_model.generate(**inputs, max_new_tokens=100, temperature=0.7)\n    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Answer\")[-1].strip()\n    return answer\n\ndef generate_kb_answer(query, info):\n    if not info: return None\n    return f\"**Definition:** {info['definition']}\\n\\n**Symptoms:** {info['symptoms']}\"\n\nst.title(\"MediScan AI\")\nst.markdown(\"<h3 style='margin-top:-12px;'>Medical Information Assistant</h3>\", unsafe_allow_html=True)\n\ntab1, tab2, tab3 = st.tabs([\"Medical Q&A\", \"Image Analysis\", \"About\"])\n\nwith tab1:\n    st.markdown(\"### Ask Medical Questions\")\n    \n    col1, col2 = st.columns([3, 1])\n    with col1:\n        query = st.text_input(\n            \"Question:\",\n            placeholder=\"e.g., What are the symptoms of melanoma?\",\n            label_visibility=\"collapsed\"\n        )\n    with col2:\n        btn = st.button(\"Ask\", type=\"primary\", use_container_width=True)\n    \n    with st.expander(\"Examples\"):\n        st.markdown(\"\"\"\n        - What are symptoms of hypertension?\n        - How is diabetes treated?\n        - What causes melanoma?\n        - When to see doctor for skin lesion?\n        \"\"\")\n    \n    if query and (btn or query):\n        with st.spinner(\"Processing...\"):\n            cond, info = find_condition(query)\n            \n            if info:\n                ai_ans = generate_answer(query, info) if text_model else None\n                kb_ans = generate_kb_answer(query, info)\n                \n                st.markdown(\"---\")\n                \n                if ai_ans:\n                    st.markdown('<div class=\"ai-response\">', unsafe_allow_html=True)\n                    st.markdown(f\"**AI Response:**\\n\\n{ai_ans}\")\n                    st.markdown('</div>', unsafe_allow_html=True)\n                    \n                    with st.expander(\"View Detailed Reference\"):\n                        st.markdown(kb_ans)\n                else:\n                    st.markdown(f\"**Medical Information:**\\n\\n{kb_ans}\")\n                \n                st.markdown(\"---\")\n                st.success(\"Educational information only. Consult healthcare professional.\")\n            else:\n                st.warning(\"No info available. Try: hypertension, melanoma, diabetes, skin cancer, lesions.\")\n\nwith tab2:\n    st.markdown(\"### Lesion Segmentation\")\n    file = st.file_uploader(\"Upload skin image\", type=['jpg', 'jpeg', 'png'], label_visibility=\"collapsed\")\n    \n    if file and vision_model:\n        try:\n            bytes_img = np.asarray(bytearray(file.read()), dtype=np.uint8)\n            img = cv2.imdecode(bytes_img, cv2.IMREAD_COLOR)\n            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            inp = cv2.resize(img, (128, 128))\n            tensor = torch.from_numpy(inp).permute(2,0,1).float().unsqueeze(0).cuda() / 255.0\n            \n            with torch.no_grad():\n                pred = vision_model(tensor)\n                mask = (torch.sigmoid(pred).cpu().numpy()[0][0] > 0.5).astype(np.uint8) * 255\n            \n            pixels_detected = np.count_nonzero(mask)\n            total_pixels = mask.size\n            percentage = (pixels_detected / total_pixels) * 100\n\n            col1, col2 = st.columns(2)\n            with col1:\n                st.image(img_rgb, use_container_width=True, caption=\"Original Image\")\n            with col2:\n                st.image(mask, use_container_width=True, caption=\"Segment Detected\")\n            \n            st.markdown(f\"\"\"\n                <div class=\"summary-box\">\n                    <h4>Analysis Summary</h4>\n                    <p><b>Lesion Coverage:</b> {percentage:.2f}% of the analyzed area.</p>\n                    <p><b>What this means:</b> The AI has identified a distinct region of interest based on pixel contrast and texture. A higher percentage may indicate a larger surface involvement.</p>\n                    <p style=\"color:#b91c1c !important; font-weight:600;\">Disclaimer: This is an automated segmentation. Please consult a dermatologist for a clinical diagnosis.</p>\n                </div>\n            \"\"\", unsafe_allow_html=True)\n\n        except Exception as e:\n            st.error(f\"Error: {e}\")\n\nwith tab3:\n    st.markdown(\"### About MediScan AI\")\n    st.markdown(\"\"\"\n    Educational AI combining Llama 3.2 3B Instruct with U-Net vision model.\n    \n    **Technology:**\n    - Llama 3.2 3B Instruct\n    - U-Net + ResNet18\n    - HAM10000 dataset\n    \n    **Limitations:**\n    - Research prototype. Not clinically validated.\n    \"\"\")\n\nst.markdown(\"\"\"\n    <div class=\"footer\">\n        This is not medical advice. Consult a specialist for proper consultation and diagnosis.\n    </div>\n\"\"\", unsafe_allow_html=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T14:01:49.532949Z","iopub.execute_input":"2026-01-11T14:01:49.533647Z","iopub.status.idle":"2026-01-11T14:01:49.544894Z","shell.execute_reply.started":"2026-01-11T14:01:49.533620Z","shell.execute_reply":"2026-01-11T14:01:49.544208Z"}},"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#Used ngrok\n\n!pip install pyngrok --quiet\n\nfrom kaggle_secrets import UserSecretsClient\nfrom pyngrok import ngrok\n\nuser_secrets = UserSecretsClient()\nngrok_token = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\n\n!ngrok authtoken {ngrok_token}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T14:01:53.062572Z","iopub.execute_input":"2026-01-11T14:01:53.063120Z","iopub.status.idle":"2026-01-11T14:01:57.955421Z","shell.execute_reply.started":"2026-01-11T14:01:53.063095Z","shell.execute_reply":"2026-01-11T14:01:57.954780Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import time, os\nfrom pyngrok import ngrok\n\n!pkill -f streamlit\n\nprint(\"Starting Streamlit...\")\nos.system(\"nohup streamlit run app.py --server.port 8501 --server.headless true > logs.txt 2>&1 &\")\n\ntime.sleep(30) \n\nprint(\"Creating ngrok tunnel...\")\npublic_url = ngrok.connect(8501, \"http\")\nprint(\"Interactive Streamlit app is live at:\", public_url)\nprint(\"Open the URL above (wait 10-30s if needed). Widgets should now be clickable!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T14:02:02.294697Z","iopub.execute_input":"2026-01-11T14:02:02.295374Z","iopub.status.idle":"2026-01-11T14:02:33.117397Z","shell.execute_reply.started":"2026-01-11T14:02:02.295339Z","shell.execute_reply":"2026-01-11T14:02:33.116662Z"}},"outputs":[{"name":"stdout","text":"Starting Streamlit...\nCreating ngrok tunnel...\nInteractive Streamlit app is live at: NgrokTunnel: \"https://simon-nontraveling-gerundively.ngrok-free.dev\" -> \"http://localhost:8501\"\nOpen the URL above (wait 10-30s if needed). Widgets should now be clickable!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}